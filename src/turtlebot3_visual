#!/usr/bin/env python

# Copyright (c) 2020, zyq_hit, Inc.
# All rights reserved.
# This is a simple example for formation

from geometry_msgs.msg import Twist
from nav_msgs.msg import Odometry
import select as se
from numpy import *
import traceback
import sys, os
import rospy
import math
import tf
import cv2
import datetime

if os.name == 'nt':
  import msvcrt
else:
  import tty, termios

from turtlebot.turtlebot_class import*    # import the turylrbot_class  
from turtlebot.turtlebot_visual import*



def getKey():                             # get keyboard value
    if os.name == 'nt':
      return msvcrt.getch()

    tty.setraw(sys.stdin.fileno())
    rlist, _, _ = se.select([sys.stdin], [], [], 0.1)
    if rlist:
        key = sys.stdin.read(1)
    else:
        key = ''

    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, settings)
    return key



if __name__=="__main__":                 # main function
    if os.name != 'nt':
        settings = termios.tcgetattr(sys.stdin)
    rospy.init_node('turtlebot3_telep') #init a ros node
    Num=3
    agent=[]
    for i in range(0,Num):
        tb=turtlebot(i)                    #init a instance of turtlebot class                 
        agent.append(tb)
    ros_rate=rospy.Rate(50)             #set the cycle Time   
    lower_red = array([100, 43,46])
    upper_red = array([180, 255, 255])
    lower_blue = array([0, 43,46])
    upper_blue = array([50, 255, 255])
    arget_center=[(961.6495971679688, 671.3650512695312), 
                  (795.37548828125, 671.2860107421875), 
                  (961.6415405273438, 563.2236328125), 
                  (795.3990478515625, 563.2208862304688)]
    

    ud=896
    vd=429
    zi=0.07
    au=camera_matrix[0,0]
    av=camera_matrix[1,1]
    u0=camera_matrix[0,2]
    v0=camera_matrix[1,2]
    Velo_ij=0
    u_ij=0
    v_ij=0
    delta_uv=matrix([ [0.0],      # pixel error
                      [0.0]])  
    image_uv=matrix([ [0.0],      # uv
                      [0.0],
                      [1.0]]) 
    gij=matrix([ [0.0],   
                 [0.0]]) 
    M_ij=matrix([ [0.0],   
                 [0.0],
                 [1.0]]) 
    Gij=matrix([ [0.0,0.0],   
                  [0.0,0.0]]) 


    try:  
        while(1):  
            agent[0].turtlebot_control(0.1,-0.01)
            feature_center=[]  
            ellipse_center=[]
            ellipse_y=[]
            ellipse_x=[]    
            target_position=[]  
            Point3D=[]
            No_list=array([0.0,0.0,0.0,0.0])
            
            # params = cv2.SimpleBlobDetector_Params()
            # params.filterByCircularity =False
            # params.minCircularity = 0.1
            # params.blobColor=255
            # detector = cv2.SimpleBlobDetector_create(params)

            hsv_image=cv2.cvtColor(agent[2].rgb_image,cv2.COLOR_RGB2HSV)
            u_ij,v_ij=calcCenterfromColorRec(hsv_image,lower_blue,upper_blue)
            target_position.append(getxyz(u_ij,v_ij,agent[2].depth_image[v_ij,u_ij],camera_param))
            suc,feature_center,Point3D=calcCenterfromEllipse(agent[2],hsv_image,lower_red, upper_red)
            if(suc):
                
                H, mask = cv2.findHomography(array(arget_center), array(feature_center), 0,5.0)
                R=calcRTfromHomo(H)
                success,rvec,tvec=cv2.solvePnP(array(Point3D),array(arget_center),camera_matrix,distCoeffD)

                theta_ij=rvec[1][0]
                theta_ij=agent[2].angular_vel_judge(theta_ij)
                image_uv[0,0]=u_ij
                image_uv[1,0]=v_ij
                Mij=dot(linalg.inv(camera_matrix),image_uv)
                qij=Mij[1,0]
                pij=Mij[0,0]
                gij[0,0]=(au*math.sin(theta_ij)-(u0-u_ij)*math.cos(theta_ij))*qij
                gij[1,0]=-(v0-v_ij)*math.cos(theta_ij)*qij
                delta_uv[0,0]=u_ij-ud
                delta_uv[1,0]=v_ij-vd
                Velo_ij=Velo_ij+0.02*(-0.0001*Velo_ij+1/zi*0.00002*delta_uv.T*gij)
                Gij[0,0]=1/zi*(u0-u_ij)*qij
                Gij[0,1]=au-(u0-u_ij)*pij
                Gij[1,0]=1/zi*(v0-v_ij)*qij
                Gij[1,1]=-(u0-u_ij)*pij
                control=Gij.I*(-0.1*delta_uv-1/zi*gij* Velo_ij)
                agent[2].turtlebot_control(control[0,0],control[1,0])


                cv2.putText(agent[2].rgb_image, str("v:")+str( Velo_ij[0,0]), (int(feature_center[0][0])+100, int(feature_center[0][1])+120), font, 1.0, (0, 0, 255), 2)
                cv2.putText(agent[2].rgb_image, str("x:")+str( target_position[0][2]), (int(feature_center[0][0])+100, int(feature_center[0][1])), font, 1.0, (0, 0, 255), 2)
                cv2.putText(agent[2].rgb_image, str("y:")+str( target_position[0][1]), (int(feature_center[0][0])+100, int(feature_center[0][1])+30), font, 1.0, (0, 0, 255), 2)
                cv2.putText(agent[2].rgb_image, str("z:")+str( target_position[0][0]), (int(feature_center[0][0])+100, int(feature_center[0][1])+60), font, 1.0, (0, 0, 255), 2)
                cv2.putText(agent[2].rgb_image, str("theta:")+str( rvec[1][0]), (int(feature_center[0][0])+100, int(feature_center[0][1])+90), font, 1.0, (0, 0, 255), 2)
                print(cameraPoseFromHomography(H))

            # time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            # print(time)
            # imshow("123", agent[2].rgb_image)
            # waitKey(1)          
            key = getKey() #get the keyboard value when input is ctrl+c then exit 
            if (key == '\x03'):
                for i in range(0,Num):
                    agent[i].turtlebot_control(0,0)
                break
            ros_rate.sleep()
    
        
    except Exception as e:
        print(e)
        

    finally:
        for i in range(0,Num):
            agent[i].turtlebot_control(0,0)


    if os.name != 'nt':
        termios.tcsetattr(sys.stdin, termios.TCSADRAIN, settings)
